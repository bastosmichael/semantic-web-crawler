//============================================================================
// Name        : SWC.cpp
// Author      : Michael Bastos
// Version     :
// Copyright   : This is open source software
// Description : C++ Crawler
//============================================================================

#include <iostream>
#include <vector>
#include <string>
#include <cstdlib>
#include <locale>
#include <sstream>
#include <sys/stat.h>
#include <sys/types.h>
#include <fstream>
using namespace std;
vector<string> page;
vector<string> regex;
void generateUrlHash(std::string urls);
void downloadUrl (const char *path, string url, string urlhash);
void loadPage(const char *p, string url, string urlhash);
void parsePage(vector<string> page);
void parseLine(string line);
void processArguments(std::string inputs);
void checkForCacheFolder();

int main(int argc, char *argv[])
{
	checkForCacheFolder();
    // Loop through each argument and print its number and value
    for (int i=0; i < argc; i++){
        processArguments(argv[i]);
    }

    return 0;
}

void checkForCacheFolder(){
	if(mkdir("cache",0777)==-1)//creating a directory
		{
		        //cerr<<"Caching..." <<endl;
		}
}

void processArguments(std::string inputs){
	if(inputs.find("SWC") != string::npos){
		//Removes initial program argument ./SWC
	} else if(inputs.find("http://") != string::npos){
		generateUrlHash(inputs);
		parsePage(page);
	} else if(inputs.find("p=") != string::npos){
		cout << "Start Pagination at: " << inputs << endl;
	} else if(inputs.find("i=") != string::npos){
		cout << "Start Item at: " << inputs << endl;
	} else {
		cout << inputs << endl;
	}
}

void generateUrlHash(std::string urls){
	locale loc;
	const collate<char>& coll = use_facet<collate<char> >(loc);
	long urlhash = coll.hash(urls.data(),urls.data()+urls.length());
	std::string hash;
	std::stringstream strstream;
	strstream << urlhash;
	strstream >> hash;
	string path = "cache/" + hash;
	const char *p;
	p=path.c_str();
	//cout << p << endl;
	cout << " " << urls << " " << hash << endl;
   	loadPage(p,urls,hash);
}

void downloadUrl (const char *path, string url, string urlhash){
	std::string command = "cd cache && wget " + url + " --output-document=" + urlhash + " --continue --force-html";
	system(command.c_str());
	//cout << command << endl;
	loadPage(path,url,urlhash);
}

void loadPage(const char *path, string url, string urlhash){
	string line;
	ifstream read (path);//reading a file
	if (read.is_open()) {
		while (! read.eof() ) {
			getline (read,line);
			page.push_back (line);
			//cout<<line<<endl;
	    }
	    read.close();
	} else {
		downloadUrl(path,url,urlhash);
	}
}

void parsePage(vector<string> page){
	for (vector<string>::iterator line = page.begin();line != page.end();++line)
	{
		parseLine(*line);
	}
}

void parseLine(string line){
	//cout << line << endl;
}
